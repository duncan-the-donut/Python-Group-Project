{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duncan-the-donut/Python-Group-Project/blob/main/X_Documentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up the Google Drive and Import Packages\n",
        "\n"
      ],
      "metadata": {
        "id": "L7Cx1PS8IULc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8s7QhSBYRx0Y"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "import tweepy\n",
        "from datetime import datetime, timedelta"
      ],
      "metadata": {
        "id": "oDqGlm5ZRzpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Access the X API"
      ],
      "metadata": {
        "id": "iPKMFcUVIfIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Replace the \"\" with the actual keys retrieved from the developer portal. They should be long strings of digits and letters.\n",
        "client = tweepy.Client(bearer_token=\"bearer token\",\n",
        "                       consumer_key=\"consumer key\",\n",
        "                       consumer_secret=\"consumer secret\",\n",
        "                       access_token=\"access token\",\n",
        "                       access_token_secret=\"access token secret\")\n",
        "\n",
        "PATH = \"/content/drive/\"\n"
      ],
      "metadata": {
        "id": "2cccqDP5R09E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Functions"
      ],
      "metadata": {
        "id": "69DR8P4OIksk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The function below is for retrieving ALL the tweets from a single user within a defined time frame. It has several checks within it in case the connection to the API times out or the rate or post limit is exceeded.\n",
        "#For each tweet, this request will retrieve all relevant information allowed by the API v2, including information about the account which posted it.\n",
        "def get_tweets_in_timeframe(client, user_id, start_date, end_date, retries=3, backoff_factor=2):\n",
        "    # Convert dates to the correct format\n",
        "    start_date_str = start_date.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
        "    end_date_str = (end_date + timedelta(days=1)).strftime('%Y-%m-%dT%H:%M:%SZ')  # Add one day to include end_date\n",
        "\n",
        "    tweets_data = []\n",
        "    next_token = None\n",
        "\n",
        "    while True:\n",
        "        for attempt in range(retries):\n",
        "            try:\n",
        "                # Fetch tweets within the date range\n",
        "                response = client.get_users_tweets(\n",
        "                    id=user_id,\n",
        "                    start_time=start_date_str,\n",
        "                    end_time=end_date_str,\n",
        "                    tweet_fields=['id', 'created_at', 'text', 'public_metrics', 'author_id', 'conversation_id', 'entities', 'geo', 'in_reply_to_user_id', 'lang', 'possibly_sensitive', 'referenced_tweets', 'source', 'attachments', 'withheld'],\n",
        "                    user_fields=['id', 'name', 'username', 'location', 'description', 'verified', 'profile_image_url', 'public_metrics'],\n",
        "                    expansions=['author_id'],\n",
        "                    max_results=100,\n",
        "                    pagination_token=next_token\n",
        "                )\n",
        "                break  # If request is successful, exit the loop\n",
        "            except (ConnectionError, Timeout, TooManyRequests) as e:\n",
        "                print(f\"Attempt {attempt + 1} failed: {e}\")\n",
        "                if attempt < retries - 1:\n",
        "                    sleep_time = backoff_factor * (2 ** attempt)\n",
        "                    print(f\"Retrying in {sleep_time} seconds...\")\n",
        "                    time.sleep(sleep_time)\n",
        "                else:\n",
        "                    print(\"Max retries reached. Moving on.\")\n",
        "                    return tweets_data\n",
        "\n",
        "        if response.data is None:\n",
        "            print(f\"No tweets found for user_id {user_id} in the specified date range.\")\n",
        "            return tweets_data\n",
        "\n",
        "        users = {u['id']: u for u in response.includes['users']} if 'users' in response.includes else {}\n",
        "\n",
        "        for tweet in response.data:\n",
        "            author = users.get(tweet.author_id)\n",
        "            tweets_data.append({\n",
        "                'id': tweet.id,\n",
        "                'created_at': tweet.created_at.replace(tzinfo=None),  # Make datetime timezone naive\n",
        "                'text': tweet.text,\n",
        "                'retweet_count': tweet.public_metrics['retweet_count'],\n",
        "                'reply_count': tweet.public_metrics['reply_count'],\n",
        "                'like_count': tweet.public_metrics['like_count'],\n",
        "                'quote_count': tweet.public_metrics['quote_count'],\n",
        "                'author_id': tweet.author_id,\n",
        "                'conversation_id': tweet.conversation_id,\n",
        "                'entities': tweet.entities,\n",
        "                'geo': tweet.geo,\n",
        "                'in_reply_to_user_id': tweet.in_reply_to_user_id,\n",
        "                'lang': tweet.lang,\n",
        "                'possibly_sensitive': tweet.possibly_sensitive,\n",
        "                'referenced_tweets': tweet.referenced_tweets,\n",
        "                'source': tweet.source,\n",
        "                'attachments': tweet.attachments,\n",
        "                'withheld': tweet.withheld,\n",
        "                'author_name': author['name'] if author else None,\n",
        "                'author_username': author['username'] if author else None,\n",
        "                'author_location': author['location'] if author else None,\n",
        "                'author_description': author['description'] if author else None,\n",
        "                'author_verified': author['verified'] if author else None,\n",
        "                'author_profile_image_url': author['profile_image_url'] if author else None,\n",
        "                'author_followers_count': author['public_metrics']['followers_count'] if author else None,\n",
        "                'author_following_count': author['public_metrics']['following_count'] if author else None,\n",
        "                'author_tweet_count': author['public_metrics']['tweet_count'] if author else None,\n",
        "                'author_listed_count': author['public_metrics']['listed_count'] if author else None\n",
        "            })\n",
        "\n",
        "        next_token = response.meta.get('next_token')\n",
        "        if not next_token:\n",
        "            break\n",
        "\n",
        "    print(f\"Number of tweets retrieved for user_id {user_id}: {len(tweets_data)}\")\n",
        "    return tweets_data\n",
        "\n",
        "def export_to_excel(tweets_data, filename):\n",
        "    # Convert the list to a DataFrame\n",
        "    df = pd.DataFrame(tweets_data)\n",
        "    # Define the path to save the file to Google Drive\n",
        "    file_path = f'/content/drive/My Drive/{filename}'\n",
        "    # Export the DataFrame to an Excel file\n",
        "    df.to_excel(file_path, index=False)\n",
        "    print(f\"Tweets data exported to {file_path}\")"
      ],
      "metadata": {
        "id": "291FDcH10Tor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set the Timeframe and Run the Functions"
      ],
      "metadata": {
        "id": "3-BCIKmcMemN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the date range\n",
        "start_date = datetime(2024, 4, 9)\n",
        "end_date = datetime(2024, 6, 9)\n",
        "\n",
        "#Replace with the username of interest\n",
        "usernames = [\"AfD\"]\n",
        "\n",
        "all_tweets_data = []\n",
        "\n",
        "for username in usernames:\n",
        "    user_get = client.get_user(username=username)\n",
        "    user_id = user_get.data.id\n",
        "    tweets_data = get_tweets_in_timeframe(client, user_id, start_date, end_date)\n",
        "    all_tweets_data.extend(tweets_data)\n"
      ],
      "metadata": {
        "id": "4xxK0da31FJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export tweets data to an Excel file\n",
        "export_to_excel(tweets_data, 'data.xlsx')"
      ],
      "metadata": {
        "id": "hzMTERr016X0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrieving Mentions"
      ],
      "metadata": {
        "id": "H8mGuHCGLWJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Be aware that these requests count towards the post limit cap\n",
        "\n",
        "import requests\n",
        "import os\n",
        "import json\n",
        "\n",
        "bearer_token = \"Bearer token\"\n",
        "\n",
        "def create_url():\n",
        "    # Replace with user ID below\n",
        "    user_id = \"user ID\"\n",
        "    return \"https://api.twitter.com/2/users/{}/mentions\".format(user_id)\n",
        "\n",
        "\n",
        "def get_params():\n",
        "    return {\"tweet.fields\": \"created_at,author_id\"}\n",
        "\n",
        "\n",
        "def bearer_oauth(r):\n",
        "    \"\"\"\n",
        "    Method required by bearer token authentication.\n",
        "    \"\"\"\n",
        "\n",
        "    r.headers[\"Authorization\"] = f\"Bearer {bearer_token}\"\n",
        "    r.headers[\"User-Agent\"] = \"v2UserMentionsPython\"\n",
        "    return r\n",
        "\n",
        "\n",
        "def connect_to_endpoint(url, params):\n",
        "    response = requests.request(\"GET\", url, auth=bearer_oauth, params=params)\n",
        "    print(response.status_code)\n",
        "    if response.status_code != 200:\n",
        "        raise Exception(\n",
        "            \"Request returned an error: {} {}\".format(\n",
        "                response.status_code, response.text\n",
        "            )\n",
        "        )\n",
        "    return response.json()\n",
        "\n",
        "\n",
        "def main():\n",
        "    url = create_url()\n",
        "    params = get_params()\n",
        "    json_response = connect_to_endpoint(url, params)\n",
        "    print(json.dumps(json_response, indent=4, sort_keys=True))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "-zDTAfeQ4lI1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}